{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATEFORMAT = \"%Y-%m-%d %H:%M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_from_utc(utc_time):\n",
    "    \"\"\"\n",
    "    Convert from UTC to datetime object\n",
    "    \"\"\"\n",
    "    return datetime.utcfromtimestamp(utc_time)\n",
    "\n",
    "def convert_to_datetime(inputdt):\n",
    "    \"\"\"\n",
    "    Return datetime object with date for parameter\n",
    "    \"\"\"\n",
    "    return datetime.strftime(inputdt, DATEFORMAT)\n",
    "\n",
    "def convert_time(utc_time):\n",
    "    return convert_to_datetime(convert_from_utc(utc_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = 1386623654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dt = convert_from_utc(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-12-09 21:14'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_time(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_repo_files(output, body=True):\n",
    "    # read in all comment files from comment folder\n",
    "    file_dir = '../../data/final/comments'\n",
    "    # directory of comments\n",
    "        \n",
    "    # extract data from repo files\n",
    "    print('Getting REPO Data...')\n",
    "    for sub_file in os.listdir(file_dir):\n",
    "        filename = sub_file[:-5]\n",
    "        print('parsing {}...'.format(sub_file))\n",
    "        \n",
    "        file_path = file_dir + '/' + sub_file\n",
    "        \n",
    "        # open each file and parse\n",
    "        with open(file_path,'r') as f:\n",
    "            # load data\n",
    "            file_data = json.load(f)\n",
    "            \n",
    "            # output print example if needed\n",
    "            #pprint(file_data['1'])\n",
    "            \n",
    "            # for each entry\n",
    "            for entry in file_data.keys():\n",
    "                # load comment data into comment variable\n",
    "                comment = file_data[entry]\n",
    "                #pprint(comment)\n",
    "                \n",
    "                # create dict to hold comment dictionary info\n",
    "                comment_dict = dict()\n",
    "                \n",
    "                #pprint(comment['author'])\n",
    "                \n",
    "                # error handle to ensure all are parsed\n",
    "                try:\n",
    "                    comment_dict['author_id'] = str(comment['author'])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['subreddit'] = filename\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['time'] = str(convert_time(comment['time']))\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['link_id'] = str(comment['link_id'])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['parent_id'] = str(comment['parent_id'])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['score'] = str(int(comment['ups']) - int(comment['downs']))\n",
    "                except:\n",
    "                    pass\n",
    "                if body:\n",
    "                    try:\n",
    "                        comment_dict['body'] = str(comment['body'])\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                #print(comment_dict)\n",
    "                #print('\\n')\n",
    "                \n",
    "                output[comment['id']] = comment_dict\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_api_files(output, body=True):\n",
    "    # read in all comment files from comment folder\n",
    "    api_dir = '../../data/final/api_data'\n",
    "\n",
    "    # directory of comments\n",
    "    \n",
    "    # extract data from reddit API\n",
    "    print('Getting API Data...')\n",
    "    for sub_file in os.listdir(api_dir):\n",
    "        filename = sub_file[:-5]\n",
    "        print('parsing {}...'.format(sub_file))\n",
    "        \n",
    "        file_path = api_dir + '/' + sub_file\n",
    "        \n",
    "        # open each file and parse\n",
    "        with open(file_path,'r') as f:\n",
    "            # load data\n",
    "            file_data = json.load(f)\n",
    "            \n",
    "            # output print example if needed\n",
    "            #pprint(file_data['1'])\n",
    "            #break\n",
    "            # for each entry\n",
    "            for entry in file_data.keys():\n",
    "\n",
    "                # load comments list into comment variable\n",
    "                comments = file_data[entry]['comments']\n",
    "                \n",
    "                # iterate through each comment\n",
    "                for comment in comments:\n",
    "                    # create dict to hold comment dictionary info\n",
    "                    comment_dict = dict()\n",
    "\n",
    "                    # error handle to ensure all are parsed\n",
    "                    try:\n",
    "                        if comment[2] == '' or comment[2] == ' ':\n",
    "                            comment_dict['author_id'] = '[deleted]'\n",
    "                        else:\n",
    "                            comment_dict['author_id'] = comment[2]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['subreddit'] = filename\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['time'] = comment[0][:-3]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['link_id'] = comment[6]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['parent_id'] = comment[7]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['score'] = comment[4]\n",
    "                    except:\n",
    "                        pass\n",
    "                    if body:\n",
    "                        try:\n",
    "                            comment_dict['body'] =  comment[3]\n",
    "                        except:\n",
    "                            pass\n",
    "                    output[comment[1]] = comment_dict\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_output(output, body=True):\n",
    "    # write data out to disk\n",
    "    print('writing data to disk...')\n",
    "    \n",
    "    if body:\n",
    "        out_path = '../../data/final/output/comments.json'\n",
    "    else:\n",
    "        out_path = '../../data/final/output/comments-no-body.json'\n",
    "    with open(out_path,'w') as f:\n",
    "        json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_comment_files(body=True):\n",
    "    output = dict()\n",
    "    \n",
    "    output = parse_repo_files(output,body)\n",
    "    output = parse_api_files(output,body)\n",
    "    write_output(output,body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting REPO Data...\n",
      "parsing bitcoinbeginners.json...\n",
      "parsing bitcoincash.json...\n",
      "parsing bitcoindiscussion.json...\n",
      "parsing bitcoinmarkets.json...\n",
      "parsing bitcoinmining.json...\n",
      "parsing bitcointechnology.json...\n",
      "parsing bitcointrading.json...\n",
      "parsing btc.json...\n",
      "parsing cryptocurrency.json...\n",
      "parsing cryptomarkets.json...\n",
      "parsing cryptotrade.json...\n",
      "parsing ethanalysis.json...\n",
      "parsing ethdapps.json...\n",
      "parsing ethdev.json...\n",
      "parsing ethereum.json...\n",
      "parsing ethereumcommunity.json...\n",
      "parsing ethereumnoobies.json...\n",
      "parsing ethermining.json...\n",
      "parsing ethinsider.json...\n",
      "parsing ethinvestor.json...\n",
      "parsing ethtrader.json...\n",
      "parsing ethtraderpro.json...\n",
      "parsing gpumining.json...\n",
      "parsing bitcoin.json...\n",
      "Getting API Data...\n",
      "parsing ethereumcommunity.json...\n",
      "parsing bitcointrading.json...\n",
      "parsing btc.json...\n",
      "parsing cryptocurrency.json...\n",
      "parsing cryptomarkets.json...\n",
      "parsing cryptotrade.json...\n",
      "parsing ethanalysis.json...\n",
      "parsing ethdapps.json...\n",
      "parsing ethdev.json...\n",
      "parsing ethereum.json...\n",
      "parsing ethereumnoobies.json...\n",
      "parsing ethermining.json...\n",
      "parsing ethinsider.json...\n",
      "parsing ethinvestor.json...\n",
      "parsing ethtrader.json...\n",
      "parsing ethtraderpro.json...\n",
      "parsing gpumining.json...\n",
      "parsing bitcoin.json...\n",
      "parsing bitcoinbeginners.json...\n",
      "parsing bitcoincash.json...\n",
      "parsing bitcoindiscussion.json...\n",
      "parsing bitcoinmarkets.json...\n",
      "parsing bitcoinmining.json...\n",
      "parsing bitcointechnology.json...\n",
      "writing data to disk...\n"
     ]
    }
   ],
   "source": [
    "parse_comment_files(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting REPO Data...\n",
      "parsing bitcoinbeginners.json...\n",
      "parsing bitcoincash.json...\n",
      "parsing bitcoindiscussion.json...\n",
      "parsing bitcoinmarkets.json...\n",
      "parsing bitcoinmining.json...\n",
      "parsing bitcointechnology.json...\n",
      "parsing bitcointrading.json...\n",
      "parsing btc.json...\n",
      "parsing cryptocurrency.json...\n",
      "parsing cryptomarkets.json...\n",
      "parsing cryptotrade.json...\n",
      "parsing ethanalysis.json...\n",
      "parsing ethdapps.json...\n",
      "parsing ethdev.json...\n",
      "parsing ethereum.json...\n",
      "parsing ethereumcommunity.json...\n",
      "parsing ethereumnoobies.json...\n",
      "parsing ethermining.json...\n",
      "parsing ethinsider.json...\n",
      "parsing ethinvestor.json...\n",
      "parsing ethtrader.json...\n",
      "parsing ethtraderpro.json...\n",
      "parsing gpumining.json...\n",
      "parsing bitcoin.json...\n",
      "Getting API Data...\n",
      "parsing ethereumcommunity.json...\n",
      "parsing bitcointrading.json...\n",
      "parsing btc.json...\n",
      "parsing cryptocurrency.json...\n",
      "parsing cryptomarkets.json...\n",
      "parsing cryptotrade.json...\n",
      "parsing ethanalysis.json...\n",
      "parsing ethdapps.json...\n",
      "parsing ethdev.json...\n",
      "parsing ethereum.json...\n",
      "parsing ethereumnoobies.json...\n",
      "parsing ethermining.json...\n",
      "parsing ethinsider.json...\n",
      "parsing ethinvestor.json...\n",
      "parsing ethtrader.json...\n",
      "parsing ethtraderpro.json...\n",
      "parsing gpumining.json...\n",
      "parsing bitcoin.json...\n",
      "parsing bitcoinbeginners.json...\n",
      "parsing bitcoincash.json...\n",
      "parsing bitcoindiscussion.json...\n",
      "parsing bitcoinmarkets.json...\n",
      "parsing bitcoinmining.json...\n",
      "parsing bitcointechnology.json...\n",
      "writing data to disk...\n"
     ]
    }
   ],
   "source": [
    "parse_comment_files(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_comment_files_old():\n",
    "    # read in all comment files from comment folder\n",
    "    file_dir = '../../data/final/comments'\n",
    "    api_dir = '../../data/final/api_data'\n",
    "    out_path = '../../data/final/output'\n",
    "    # directory of comments\n",
    "    \n",
    "    output = dict()\n",
    "    \n",
    "    # extract data from repo files\n",
    "    for sub_file in os.listdir(file_dir):\n",
    "        filename = sub_file[:-5]\n",
    "        print('parsing {}...'.format(sub_file))\n",
    "        \n",
    "        file_path = file_dir + '/' + sub_file\n",
    "        \n",
    "        # open each file and parse\n",
    "        with open(file_path,'r') as f:\n",
    "            # load data\n",
    "            file_data = json.load(f)\n",
    "            \n",
    "            # output print example if needed\n",
    "            pprint(file_data['1'])\n",
    "            \n",
    "            # for each entry\n",
    "            for entry in file_data.keys():\n",
    "                # load comment data into comment variable\n",
    "                comment = file_data[entry]\n",
    "                # create dict to hold comment dictionary info\n",
    "                comment_dict = dict()\n",
    "\n",
    "                # error handle to ensure all are parsed\n",
    "                try:\n",
    "                    comment_dict['author_id'] = entry_data['author']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['subreddit'] = filename\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['time'] = convert_time(entry_data['time'])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['link_id'] = entry_data['link_id']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['parent_id'] = entry_data['parent_id']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['score'] = entry_data['ups'] - entry_data['downs']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['body'] = entry_data['body']\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                output[comment['id']] = comment_dict\n",
    "\n",
    "    # extract data from reddit API\n",
    "    print('\\nGetting API Data...')\n",
    "    for sub_file in os.listdir(api_dir):\n",
    "        filename = sub_file[:-5]\n",
    "        print('parsing {}...'.format(sub_file))\n",
    "        \n",
    "        file_path = api_dir + '/' + sub_file\n",
    "        \n",
    "        # open each file and parse\n",
    "        with open(file_path,'r') as f:\n",
    "            # load data\n",
    "            file_data = json.load(f)\n",
    "            \n",
    "            # output print example if needed\n",
    "            #pprint(file_data['1'])\n",
    "            #break\n",
    "            # for each entry\n",
    "            for entry in file_data.keys():\n",
    "\n",
    "                # load comments list into comment variable\n",
    "                comments = file_data[entry]['comments']\n",
    "                i = 0\n",
    "                # iterate through each comment\n",
    "                for comment in comments:\n",
    "                    # create dict to hold comment dictionary info\n",
    "                    comment_dict = dict()\n",
    "\n",
    "                    # error handle to ensure all are parsed\n",
    "                    try:\n",
    "                        comment_dict['author_id'] = comment[2]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['subreddit'] = filename\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['time'] = comment[0][:-3]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['link_id'] = comment[6]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['parent_id'] = comment[7]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['score'] = comment[4]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['body'] =  comment[3]\n",
    "                    except:\n",
    "                        pass\n",
    "                    output[comment[1]] = comment_dict\n",
    "    \n",
    "    # write data out to disk\n",
    "    print('writing data to disk...')\n",
    "    with open(out_path + '/comments2.json','w') as f:\n",
    "        json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitcoinbeginners.json\tbtc.json\t\tethereum.json\r\n",
      "bitcoincash.json\tcryptocurrency.json\tethereumnoobies.json\r\n",
      "bitcoindiscussion.json\tcryptomarkets.json\tethermining.json\r\n",
      "bitcoin.json\t\tcryptotrade.json\tethinsider.json\r\n",
      "bitcoinmarkets.json\tethanalysis.json\tethinvestor.json\r\n",
      "bitcoinmining.json\tethdapps.json\t\tethtrader.json\r\n",
      "bitcointechnology.json\tethdev.json\t\tethtraderpro.json\r\n",
      "bitcointrading.json\tethereumcommunity.json\tgpumining.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls '../../data/final/comments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_comment_files():\n",
    "    # read in all comment files from comment folder\n",
    "    file_dir = '../../data/final/comments'\n",
    "    api_dir = '../../data/final/api_data'\n",
    "    out_path = '../../data/final/output'\n",
    "    # directory of comments\n",
    "    \n",
    "    output = dict()\n",
    "    \n",
    "    # extract data from repo files\n",
    "    for sub_file in os.listdir(file_dir):\n",
    "        filename = sub_file[:-5]\n",
    "        print('parsing {}...'.format(sub_file))\n",
    "        \n",
    "        file_path = file_dir + '/' + sub_file\n",
    "        \n",
    "        # open each file and parse\n",
    "        with open(file_path,'r') as f:\n",
    "            # load data\n",
    "            file_data = json.load(f)\n",
    "            \n",
    "            # output print example if needed\n",
    "            #pprint(file_data['1'])\n",
    "            \n",
    "            # for each entry\n",
    "            for entry in file_data.keys():\n",
    "                # load comment data into comment variable\n",
    "                comment = file_data[entry]\n",
    "                # create dict to hold comment dictionary info\n",
    "                comment_dict = dict()\n",
    "\n",
    "                # error handle to ensure all are parsed\n",
    "                try:\n",
    "                    comment_dict['author_id'] = entry_data['author']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['subreddit'] = filename\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['time'] = convert_time(entry_data['time'])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['link_id'] = entry_data['link_id']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['parent_id'] = entry_data['parent_id']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['score'] = entry_data['ups'] - entry_data['downs']\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    comment_dict['body'] = entry_data['body']\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                output[comment['id']] = comment_dict\n",
    "    \n",
    "    # write data out to disk\n",
    "    print('writing data to disk...')\n",
    "    with open(out_path + '/comments.json','w') as f:\n",
    "        json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_comment_files_test():\n",
    "    # read in all comment files from comment folder\n",
    "    file_dir = '../../data/final/comments'\n",
    "    api_dir = '../../data/final/api_data'\n",
    "    out_path = '../../data/final/output'\n",
    "    # directory of comments\n",
    "    \n",
    "    output = dict()\n",
    "\n",
    "\n",
    "    # extract data from reddit API\n",
    "    print('\\nGetting API Data...')\n",
    "    for sub_file in os.listdir(api_dir):\n",
    "        filename = sub_file[:-5]\n",
    "        print('parsing {}...'.format(sub_file))\n",
    "        \n",
    "        file_path = api_dir + '/' + sub_file\n",
    "        \n",
    "        # open each file and parse\n",
    "        with open(file_path,'r') as f:\n",
    "            # load data\n",
    "            file_data = json.load(f)\n",
    "            \n",
    "            # output print example if needed\n",
    "            #pprint(file_data['1'])\n",
    "            #break\n",
    "            # for each entry\n",
    "            for entry in file_data.keys():\n",
    "\n",
    "                # load comments list into comment variable\n",
    "                comments = file_data[entry]['comments']\n",
    "\n",
    "                # iterate through each comment\n",
    "                for comment in comments:\n",
    "                    pprint(comment)\n",
    "                    # create dict to hold comment dictionary info\n",
    "                    comment_dict = dict()\n",
    "\n",
    "                    # error handle to ensure all are parsed\n",
    "                    try:\n",
    "                        comment_dict['author_id'] = comment[2]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['subreddit'] = filename\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['time'] = comment[0][:-3]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['link_id'] = comment[6]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['parent_id'] = comment[7]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['score'] = comment[4]\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        comment_dict['body'] =  comment[3]\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    output[comment[1]] = comment_dict  \n",
    "    \n",
    "   # with open(out_path + '/comments.json','w') as f:\n",
    "    #    json.dump(output, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
