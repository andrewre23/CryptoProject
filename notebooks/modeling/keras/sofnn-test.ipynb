{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "import keras as k\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import datetime as dt\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, \\\n",
    "                confusion_matrix, classification_report\n",
    "\n",
    "# custom Fuzzy Layers\n",
    "from sofenn import SOFNN\n",
    "from sofenn.layers import FuzzyLayer, NormalizedLayer, WeightedLayer, OutputLayer\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/FinalDataset.csv',index_col='date')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show closing price time series\n",
    "df['bitcoin_close'].plot(title='BTC Close Price',grid=True,rot=35, figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show log-closing price time series\n",
    "df['bitcoin_close'].plot(title='BTC Log-Close Price',grid=True,logy=True,rot=35, figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats on time series length\n",
    "print(\"number of days:  {:.1f}\".format(df.shape[0]))\n",
    "print(\"number of months:  {:.1f}\".format(df.shape[0] / 30))\n",
    "print(\"number of years:    {:.1f}\".format(df.shape[0] / 365))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read in dataset\n",
    "\n",
    "def get_data():\n",
    "    return pd.read_csv('../data/FinalDataset.csv',index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to drop unneeded fields\n",
    "\n",
    "def keep_only_close(df_in):\n",
    "    drops = ['bitcoin_open', 'bitcoin_high', 'bitcoin_low',\n",
    "             'bitcoin_volume', 'bitcoin_market_cap']\n",
    "    return df_in.drop(drops, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add predicted column for tomorrow's close price\n",
    "\n",
    "def add_prediction_field(df_in):\n",
    "    # creating predicted value\n",
    "    # create column to hold tomorrow's close for each day\n",
    "    df_in['tomorrow_close'] = df_in['bitcoin_close'].shift(-1)\n",
    "    # change in price between consecutive closing days\n",
    "    df_in['day_change'] = df_in['tomorrow_close'] - df_in['bitcoin_close']\n",
    "    # indicator variable to be used for predicting higher/lower days\n",
    "    df_in['y'] = np.where(df_in['day_change'] >= 0, 1, 0)\n",
    "        \n",
    "    # drop intermediate columns\n",
    "    return df_in.drop(['tomorrow_close', 'day_change'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve lag values to use for each feature\n",
    "\n",
    "def get_feature_lag_dict(lag_vers=1):\n",
    "    # check value of input\n",
    "    if lag_vers not in [1, 2, 3, 4]:\n",
    "        raise ValueError('Incorrect Version')\n",
    "    \n",
    "    # read in right version of file\n",
    "    df = pd.read_csv('../lags/optimal_v{}.csv'.format(lag_vers))\n",
    "    \n",
    "    # return dictionary of features as keys and lags as values\n",
    "    return dict(zip(df.feature, df.lags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add lags for daily features\n",
    "\n",
    "def add_lags(df_in, lag_vers=1):\n",
    "    # splitting into X/y for separate processing\n",
    "    X, y = df_in[df_in.columns[:-1]], df_in[df_in.columns[-1]]\n",
    "    # save list of columns for lags\n",
    "    col_list = X.columns\n",
    "    # create output DF\n",
    "    df_out = X.copy()\n",
    "    \n",
    "    # creating lags\n",
    "    f_dict = get_feature_lag_dict(lag_vers=lag_vers)\n",
    "    # create lag columns for each other variable\n",
    "    for col in col_list:\n",
    "        if col not in f_dict.keys(): continue\n",
    "        for lag in range(int(f_dict[col])):\n",
    "            df_out['{}_(-{})'.format(col,lag+1)] = df_out[col].shift(lag+1)\n",
    "\n",
    "    # return and drop na\n",
    "    df_out['y'] = y\n",
    "    return df_out.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove data before certain date\n",
    "\n",
    "def truncate_date(df_in, first_day='1999-1-1'):\n",
    "    # set mask of Bool values\n",
    "    mask = (pd.to_datetime(df_in.index) >= first_day)\n",
    "    return df_in.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rejoin training data into X/y again\n",
    "\n",
    "def rejoin_training_data(X_train, X_test, y_train, y_test):\n",
    "    Xs = [X_train, X_test]\n",
    "    Ys = [y_train, y_test]\n",
    "    \n",
    "    df_out = pd.concat(Xs)\n",
    "    df_out['y'] = pd.concat(Ys)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create train/test X and y\n",
    "def create_training_data(df_in, lag_vers=1, train_split=0.7, rescale=True, k_feat_perc=None):\n",
    "    # split into test train\n",
    "    X, y = df_in[df_in.columns[:-1]], df_in[df_in.columns[-1]]\n",
    "    \n",
    "    # determine cutoff of train/test split and split\n",
    "    cutoff = int(X.shape[0] * train_split)\n",
    "    X_train, y_train = X[:cutoff], y[:cutoff]\n",
    "    X_test, y_test = X[cutoff:], y[cutoff:]\n",
    "    \n",
    "    # scale values to 0-1\n",
    "    # must only scale based on training data, to ensure no \n",
    "    # foresight with averages\n",
    "    if rescale:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1)).fit(X_train.values)\n",
    "        cols = X.columns\n",
    "        X_train = pd.DataFrame(scaler.transform(X_train.values), \n",
    "                               index=X_train.index, columns=cols)\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test.values), \n",
    "                               index=X_test.index, columns=cols)\n",
    "    \n",
    "    # select top K features to use\n",
    "    if k_feat_perc:\n",
    "        selector = SelectPercentile(chi2, percentile=k_feat_perc).fit(\n",
    "                                    X_train.values,y_train.values)\n",
    "        # index and names of remainig columns after filter\n",
    "        cols = X_train.columns[selector.get_support(indices = True)]\n",
    "        X_train = pd.DataFrame(selector.transform(X_train.values), \n",
    "                               index=X_train.index, columns=cols)\n",
    "        X_test = pd.DataFrame(selector.transform(X_test.values), \n",
    "                               index=X_test.index, columns=cols)\n",
    "    \n",
    "    # recreate into X/y DF and add lags\n",
    "    df_renew = rejoin_training_data(X_train, X_test, y_train, y_test)\n",
    "    df_renew = add_lags(df_renew, lag_vers=lag_vers)\n",
    "    \n",
    "    # split into test train again\n",
    "    X, y = df_renew[df_renew.columns[:-1]], df_renew[df_renew.columns[-1]]\n",
    "    cutoff = int(X.shape[0] * train_split)\n",
    "    X_train, y_train = X[:cutoff], y[:cutoff]\n",
    "    X_test, y_test = X[cutoff:], y[cutoff:]\n",
    "\n",
    "    # display shapes\n",
    "    print('='*65)\n",
    "    print('New Training Set')\n",
    "    print('Training Set Dims: {}'.format(X_train.shape))\n",
    "    print('Testing Set Dims:  {}'.format(X_test.shape))\n",
    "    print('='*65)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prep data and return DF for modeling\n",
    "\n",
    "def prepare_data(lag_vers=1, train_split=0.7, close_o=False, \n",
    "                         first_day=None, rescale=True, k_feat_perc=None):\n",
    "    # read in  dataset and initialize output df\n",
    "    df_in = get_data()\n",
    "    \n",
    "    # drop non-price fields if needed\n",
    "    if close_o:\n",
    "        df_in = keep_only_close(df_in)\n",
    "    \n",
    "    # add prediction field\n",
    "    df_in = add_prediction_field(df_in)\n",
    "    \n",
    "    # cut off prior to first_day\n",
    "    if first_day:\n",
    "        df_in = truncate_date(df_in, first_day)\n",
    "    \n",
    "    return create_training_data(df_in, lag_vers=lag_vers, train_split=train_split, \n",
    "                                rescale=rescale, k_feat_perc=k_feat_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = prepare_data(lag_vers=2, train_split=0.9, close_o=False, \n",
    "                                    first_day='2016-7-1', rescale=True, k_feat_perc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance of dependent variable values\n",
    "ones = y_train.sum()\n",
    "zeros = y_train.shape[0] - ones\n",
    "print(\"0's: {}\".format(zeros))\n",
    "print(\"1's: {}\".format(ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance of dependent variable values\n",
    "ones = y_test.sum()\n",
    "zeros = y_test.shape[0] - ones\n",
    "print(\"0's: {}\".format(zeros))\n",
    "print(\"1's: {}\".format(ones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Train, Test SOFNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sofnn._train_model()\n",
    "y_pred = sofnn._evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create and train model\n",
    "\n",
    "def run_model(rules=5, batch_size = 1, epochs=5):\n",
    "    # get shape of training data\n",
    "    samples, feats = X_train.shape\n",
    "    \n",
    "    # add layers\n",
    "    inputs = Input(name='Inputs',shape=(feats,))\n",
    "    fuzz = FuzzyLayer(rules)\n",
    "    norm = NormalizedLayer(rules)\n",
    "    weights = WeightedLayer(rules)\n",
    "    raw = OutputLayer()\n",
    "    \n",
    "    # run through layers\n",
    "    phi = fuzz(inputs)\n",
    "    psi = norm(phi)\n",
    "    f = weights([inputs, psi])\n",
    "    raw_output = raw(f)\n",
    "    #raw_output = Dense(1, name='RawOutput', activation='linear', use_bias=False)(f)\n",
    "    preds = Activation(name='OutputActivation', activation='sigmoid')(raw_output)\n",
    "    \n",
    "    # compile model and output summary \n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    # fit model and evaluate\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,shuffle=False)\n",
    "    scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "    accuracy = scores[1] * 100\n",
    "    print(\"\\nAccuracy: {:.2f}%\".format(accuracy))\n",
    "    \n",
    "    # print confusion matrix\n",
    "    print('\\nConfusion Matrix')\n",
    "    print('='*20)\n",
    "    y_pred = np.squeeze(np.where(model.predict(X_test) >= 0.5, 1, 0), axis=-1)\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                       index=['true:no', 'true:yes'], columns=['pred:no', 'pred:yes']))\n",
    "    \n",
    "    # print classification report\n",
    "    print('\\nClasification Report')\n",
    "    print('='*20)\n",
    "    print(classification_report(y_test, y_pred, labels=[0,1]))\n",
    "    \n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test out various nodes\n",
    "for rule in [5]:\n",
    "    print('{} Rules'.format(rule))\n",
    "    model, y_pred = run_model(rules=rule, batch_size=30, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Initial Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test, neurons=1, \n",
    "              ksig=1.5, max_widens=250, prune_tol=0.85)\n",
    "sofnn.self_organize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Initial Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test, neurons=2, \n",
    "              ksig=1.5, max_widens=250, prune_tol=0.85)\n",
    "sofnn.self_organize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Initial Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test, neurons=3, \n",
    "              ksig=1.5, max_widens=250, prune_tol=0.85)\n",
    "sofnn.self_organize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Initial Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test, neurons=5, \n",
    "              ksig=1.5, max_widens=250, prune_tol=0.85)\n",
    "sofnn.self_organize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Initial Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test, neurons=10, \n",
    "              ksig=1.5, max_widens=250, prune_tol=0.85)\n",
    "sofnn.self_organize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Initial Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test, neurons=20, \n",
    "              ksig=1.5, max_widens=250, prune_tol=0.85)\n",
    "sofnn.self_organize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25 Initial Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test, neurons=25, \n",
    "              ksig=1.5, max_widens=250, prune_tol=0.85)\n",
    "sofnn.self_organize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 Initial Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SOFNN(X_train, X_test, y_train, y_test, neurons=50, \n",
    "              ksig=1.5, max_widens=250, prune_tol=0.85)\n",
    "sofnn.self_organize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
